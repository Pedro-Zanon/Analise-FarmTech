import sys
import os
import joblib
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_absolute_error

# --- CONFIGURAÃ‡ÃƒO DE IMPORTS ---
# Pega a pasta onde este arquivo estÃ¡ (backend)
pasta_atual = os.path.dirname(os.path.abspath(__file__))
# Define a pasta vizinha (database)
pasta_database = os.path.join(pasta_atual, '..', 'database')
# Adiciona ao sistema para conseguir importar o db_config
sys.path.append(pasta_database)

from db_config import get_db_connection

def tratar_numeros_gigantes(valor, limite_maximo):
    """
    FunÃ§Ã£o de seguranÃ§a: Se o nÃºmero for absurdamente grande (erro do sensor/banco),
    vai dividindo por 10 atÃ© ele caber no limite real.
    """
    if pd.isna(valor): return 0
    valor = float(valor)
    while valor > limite_maximo:
        valor = valor / 10.0
    return valor

def treinar_ia():
    print("\n" + "="*50)
    print("ğŸš€ INICIANDO PIPELINE (MODO BLINDADO)")
    print("="*50)

    # 1. Busca dados
    dados_lista = get_db_connection()
    if not dados_lista:
        print("âŒ Erro: Banco vazio.")
        return

    df = pd.DataFrame(dados_lista)
    print(f"ğŸ“¦ Dados Brutos: {len(df)} linhas.")
    
    if len(df) > 0:
        print(f"ğŸ” Exemplo de Umidade crua: {df['umidade'].iloc[0]}")

    # ==============================================================================
    #  LIMPEZA AUTOMÃTICA 
    # ==============================================================================
    print("ğŸ§¹ Normalizando dados gigantes automaticamente...")

    # Aplica a funÃ§Ã£o de correÃ§Ã£o
    df['umidade'] = df['umidade'].apply(lambda x: tratar_numeros_gigantes(x, 100))
    df['ph'] = df['ph'].apply(lambda x: tratar_numeros_gigantes(x, 14))
    df['temperatura'] = df['temperatura'].apply(lambda x: tratar_numeros_gigantes(x, 60))
    
    # Garante que nÃ£o tem valores negativos
    df = df.clip(lower=0)

    # CriaÃ§Ã£o de produtividade sintÃ©tica
    df['produtividade_kg'] = (
        (df['umidade'] * 12.5) +
        (df['nivel_npk'] * 8.0) +
        (df['temperatura'] * 2.0) -
        (abs(df['ph'] - 6.5) * 100)
    ) + 1000 + np.random.normal(0, 50, len(df))

    print(f"âœ… Dados Prontos: {len(df)} linhas (Nenhuma foi deletada!)")
    # ==============================================================================

    # 3. Treinamento
    X = df[['umidade', 'ph', 'temperatura', 'nivel_npk']]
    y = df['produtividade_kg']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    modelo = RandomForestRegressor(n_estimators=100, random_state=42)
    modelo.fit(X_train, y_train)

    # 4. Resultados
    previsoes = modelo.predict(X_test)
    r2 = r2_score(y_test, previsoes)
    mae = mean_absolute_error(y_test, previsoes)

    print("\nğŸ“Š RESULTADOS:")
    print(f"   ğŸ”¹ RÂ² (Nota): {r2:.4f}")
    print(f"   ğŸ”¹ Erro MÃ©dio: {mae:.2f} kg")

    # 5. Salvar na pasta DATABASE (ALTERADO AQUI)
    # Usa a variÃ¡vel pasta_database que definimos lÃ¡ no topo
    caminho_final = os.path.join(pasta_database, 'modelo_farmtech.joblib')
    
    # Normaliza o caminho para ficar bonito no print (resolve os ..)
    caminho_final = os.path.abspath(caminho_final)
    
    joblib.dump(modelo, caminho_final)
    print(f"\nğŸ’¾ SUCESSO! Modelo salvo em:\n   {caminho_final}")
    print("="*50)

if __name__ == "__main__":
    treinar_ia()